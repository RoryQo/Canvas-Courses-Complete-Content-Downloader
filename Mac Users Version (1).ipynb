{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5dd699",
   "metadata": {},
   "source": [
    "# Automated Canvas Course Content Downloader (Mac Version)\n",
    "\n",
    "This script downloads all course materials from both current and past Canvas courses using the Canvas API. It supports all file types, including `.pdf`, `.R`, `.Rmd`, `.csv`, `.ipynb`, and others. Files embedded inside pages, modules, or viewer-style links are automatically identified and downloaded. The file paths should be correct and ready to use for default installation with mac os\n",
    "\n",
    "## Setup and Usage\n",
    "\n",
    "To run this script, follow these steps:\n",
    "\n",
    "1. **Install Required Python Packages**  \n",
    "   Use pip to install the following packages:  \n",
    "   \n",
    "   - `requests`  \n",
    "   - `beautifulsoup4`  \n",
    "   - `pdfkit`\n",
    "\n",
    "<br>\n",
    "\n",
    "2. **Install `wkhtmltopdf`**  \n",
    "   This tool is required by `pdfkit` to convert HTML content (pages, assignments, modules) into PDF files.  \n",
    "   - Download and install it from: [https://wkhtmltopdf.org/downloads.html](https://wkhtmltopdf.org/downloads.html)  \n",
    "   - Default path after installation will work.\n",
    "\n",
    "3. **Generate and Add Your Canvas API Token**  \n",
    "   - Log into Canvas, go to **Account > Settings > Approved Integrations**, and generate a new token.  \n",
    "   - Paste it into the script where indicated (`API_TOKEN = '...'`).\n",
    "   - Replace `pitt` in canvas domain with your institutions canvas domain.\n",
    "\n",
    "4. **Run the Script**  \n",
    "   Open the notebook or Python script and run it. It will:\n",
    "   - Retrieve both active and completed Canvas courses\n",
    "   - Download all available files, linked content, and assignment submissions\n",
    "   - Convert Canvas-hosted HTML content into PDFs (no `.html` files are saved)\n",
    "   - Save everything to a structured local folder organized by course\n",
    "\n",
    "## Output\n",
    "\n",
    "All downloaded files are saved to a local directory named `canvas_all_content`, with one subfolder per course. Original filenames and extensions are preserved\n",
    "\n",
    "\n",
    "### Folder Structure\n",
    "\n",
    "```\n",
    "canvas_all_content/\n",
    "├── Course Name A/\n",
    "│   ├── lecture1.pdf\n",
    "│   ├── page - Syllabus.html\n",
    "│   ├── assignment - Essay.html\n",
    "│   ├── module - Week 1 Overview.html\n",
    "│   └── submission - final_essay.pdf\n",
    "├── Course Name B/\n",
    "│   └── ...\n",
    "```\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Most module and assignment PDFs may appear blank. This is expected behavior:\n",
    "  - Modules are often used as containers for linked content rather than standalone descriptions.\n",
    "  - Assignment pages are also frequently blank unless the instructor specifically writes assignment details in the Canvas page itself.\n",
    "  - These files are still processed because they often contain embedded links to downloadable materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9d054-eba7-4717-9adb-7338a5bdbdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure pdfkit is installed in the correct environment\n",
    "\n",
    "!/opt/miniconda3/envs/ba2/bin/python -m pip install pdfkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b563e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pdfkit\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebbed6d-212d-4c20-8713-131c16bf384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see the path wkhtmltopdf is installed with (if needed)\n",
    "\n",
    "    # import shutil\n",
    "\n",
    "    # wkhtmltopdf_path = shutil.which('wkhtmltopdf')\n",
    "    # print(wkhtmltopdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for wkhtmltopdf (change this path if needed)\n",
    "\n",
    "# Corrected macOS path to wkhtmltopdf\n",
    "pdfkit_config = pdfkit.configuration(wkhtmltopdf='/usr/local/bin/wkhtmltopdf')\n",
    "\n",
    "# Fill in your details\n",
    "API_TOKEN = 'Your_API_Key'\n",
    "CANVAS_DOMAIN = 'https://canvas.pitt.edu'\n",
    "BASE_API_URL = f'{CANVAS_DOMAIN}/api/v1'\n",
    "DOWNLOADS_BASE = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", \"canvas_all_content\")\n",
    "HEADERS = {'Authorization': f'Bearer {API_TOKEN}'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f362f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_file_urls = set()\n",
    "\n",
    "def make_safe(name):\n",
    "    return re.sub(r'[<>:\"/\\\\|?*]', '_', name).strip()\n",
    "\n",
    "def safe_paginate(url):\n",
    "    results = []\n",
    "    try:\n",
    "        while url:\n",
    "            r = requests.get(url, headers=HEADERS)\n",
    "            if r.status_code in [403, 404]:\n",
    "                print(f\"    Skipping ({r.status_code} error): {url}\")\n",
    "                return []\n",
    "            r.raise_for_status()\n",
    "            results.extend(r.json())\n",
    "            url = r.links.get('next', {}).get('url')\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"    Error during pagination: {e}\")\n",
    "        return []\n",
    "\n",
    "def save_html_as_pdf(folder, name, html_content):\n",
    "    safe_name = make_safe(name)\n",
    "    pdf_path = os.path.join(folder, f\"{safe_name}.pdf\")\n",
    "    try:\n",
    "        pdfkit.from_string(html_content, pdf_path, configuration=pdfkit_config)\n",
    "        print(f\"    Saved PDF: {safe_name}.pdf\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Error converting {safe_name} to PDF: {e}\")\n",
    "\n",
    "def download_canvas_file_by_id(file_id, course_folder):\n",
    "    try:\n",
    "        meta = requests.get(f\"{BASE_API_URL}/files/{file_id}\", headers=HEADERS)\n",
    "        meta.raise_for_status()\n",
    "        file_data = meta.json()\n",
    "        download_url = file_data['url']\n",
    "        filename = make_safe(file_data['display_name'])\n",
    "\n",
    "        if download_url in downloaded_file_urls:\n",
    "            return\n",
    "\n",
    "        r = requests.get(download_url, headers=HEADERS)\n",
    "        r.raise_for_status()\n",
    "        with open(os.path.join(course_folder, filename), 'wb') as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "        downloaded_file_urls.add(download_url)\n",
    "        print(f\"    ✅ Downloaded file from API: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error downloading file ID {file_id}: {e}\")\n",
    "\n",
    "def extract_and_download_linked_files(html, course_folder):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    for tag in soup.find_all(['a', 'iframe'], href=True) + soup.find_all(['a', 'iframe'], src=True):\n",
    "        href = tag.get('href') or tag.get('src')\n",
    "        if href:\n",
    "            match = re.search(r'/files/(\\d+)', href)\n",
    "            if match:\n",
    "                file_id = match.group(1)\n",
    "                download_canvas_file_by_id(file_id, course_folder)\n",
    "\n",
    "    for script in soup.find_all('script'):\n",
    "        if script.string:\n",
    "            matches = re.findall(r'/files/(\\d+)', script.string)\n",
    "            for file_id in set(matches):\n",
    "                download_canvas_file_by_id(file_id, course_folder)\n",
    "\n",
    "# === Main Workflow ===\n",
    "print(\"Fetching your Canvas courses...\")\n",
    "\n",
    "current_courses = safe_paginate(f\"{BASE_API_URL}/courses?per_page=100&enrollment_state=active\")\n",
    "completed_courses = safe_paginate(f\"{BASE_API_URL}/courses?per_page=100&enrollment_state=completed\")\n",
    "\n",
    "courses = current_courses + completed_courses\n",
    "\n",
    "\n",
    "for course in courses:\n",
    "    course_id = course['id']\n",
    "    course_name = make_safe(course.get('name') or f\"course_{course_id}\")\n",
    "    print(f\"\\nCourse: {course_name}\")\n",
    "    course_folder = os.path.join(DOWNLOADS_BASE, course_name)\n",
    "    os.makedirs(course_folder, exist_ok=True)\n",
    "\n",
    "    print(\"  Downloading files...\")\n",
    "    for file in safe_paginate(f\"{BASE_API_URL}/courses/{course_id}/files?per_page=100\"):\n",
    "        try:\n",
    "            file_url = file['url']\n",
    "            if file_url in downloaded_file_urls:\n",
    "                continue\n",
    "            r = requests.get(file_url, headers=HEADERS)\n",
    "            r.raise_for_status()\n",
    "            file_path = os.path.join(course_folder, make_safe(file['filename']))\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            downloaded_file_urls.add(file_url)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error downloading {file.get('filename', 'unknown')}: {e}\")\n",
    "\n",
    "    print(\"  Downloading pages...\")\n",
    "    for page in safe_paginate(f\"{BASE_API_URL}/courses/{course_id}/pages?per_page=100\"):\n",
    "        try:\n",
    "            detail = requests.get(f\"{BASE_API_URL}/courses/{course_id}/pages/{page['url']}\", headers=HEADERS)\n",
    "            if detail.status_code in [403, 404]:\n",
    "                continue\n",
    "            detail.raise_for_status()\n",
    "            body = detail.json().get('body', '')\n",
    "            name = f\"page - {page['title']}\"\n",
    "            extract_and_download_linked_files(body, course_folder)\n",
    "            save_html_as_pdf(course_folder, name, body)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error handling page {page['title']}: {e}\")\n",
    "\n",
    "    print(\"  Downloading assignments...\")\n",
    "    for assignment in safe_paginate(f\"{BASE_API_URL}/courses/{course_id}/assignments?per_page=100\"):\n",
    "        try:\n",
    "            description_html = assignment.get('description', '')\n",
    "            name = f\"assignment - {assignment['name']}\"\n",
    "            extract_and_download_linked_files(description_html, course_folder)\n",
    "            html = f\"<h1>{assignment['name']}</h1><p>{description_html}</p>\"\n",
    "            save_html_as_pdf(course_folder, name, html)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error handling assignment {assignment['name']}: {e}\")\n",
    "\n",
    "    print(\"  Downloading modules...\")\n",
    "    for module in safe_paginate(f\"{BASE_API_URL}/courses/{course_id}/modules?per_page=100\"):\n",
    "        try:\n",
    "            content = f\"<h1>{module['name']}</h1><ul>\"\n",
    "            items = safe_paginate(f\"{BASE_API_URL}/courses/{course_id}/modules/{module['id']}/items?per_page=100\")\n",
    "            for item in items:\n",
    "                content += f\"<li>{item['title']} ({item['type']})</li>\"\n",
    "\n",
    "                if item['type'] == 'File' and 'content_id' in item:\n",
    "                    download_canvas_file_by_id(item['content_id'], course_folder)\n",
    "\n",
    "                elif 'html_url' in item:\n",
    "                    html_url = item['html_url']\n",
    "                    item_resp = requests.get(html_url, headers=HEADERS)\n",
    "                    if item_resp.ok:\n",
    "                        extract_and_download_linked_files(item_resp.text, course_folder)\n",
    "\n",
    "                elif item.get('type') == 'Page' and 'page_url' in item:\n",
    "                    page_api_url = f\"{BASE_API_URL}/courses/{course_id}/pages/{item['page_url']}\"\n",
    "                    page_resp = requests.get(page_api_url, headers=HEADERS)\n",
    "                    if page_resp.ok:\n",
    "                        body = page_resp.json().get('body', '')\n",
    "                        extract_and_download_linked_files(body, course_folder)\n",
    "\n",
    "            content += \"</ul>\"\n",
    "            name = f\"module - {module['name']}\"\n",
    "            save_html_as_pdf(course_folder, name, content)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error saving module {module['name']}: {e}\")\n",
    "\n",
    "    print(\"  Downloading your submissions...\")\n",
    "    submissions = safe_paginate(f\"{BASE_API_URL}/courses/{course_id}/students/submissions?per_page=100\")\n",
    "    for sub in submissions:\n",
    "        for attachment in sub.get(\"attachments\", []):\n",
    "            try:\n",
    "                file_url = attachment['url']\n",
    "                if file_url in downloaded_file_urls:\n",
    "                    continue\n",
    "                filename = make_safe(f\"submission - {attachment['filename']}\")\n",
    "                r = requests.get(file_url, headers=HEADERS)\n",
    "                r.raise_for_status()\n",
    "                with open(os.path.join(course_folder, filename), 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "                downloaded_file_urls.add(file_url)\n",
    "                print(f\"    Downloaded submission: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    Error downloading submission file: {e}\")\n",
    "\n",
    "print(\"\\n✅ All course content downloaded to your Downloads/canvas_all_content folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
